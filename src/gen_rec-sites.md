# Recommended Websites

## Articles

### distill

#### Description

```info
:: Link: <https://distill.pub/>
```

#### Selected Articles

##### Attention and Augmented Recurrent Neural Networks

```info
:: Link: <https://distill.pub/2016/augmented-rnns/>
```

<!--<div class="tiles" style="display: flex; flex-flow: row wrap;">
<div style="flex-shrink: 1; max-width: 40%;"><img src="2023-12-11-21-18-52.png" style="width: 100%;"/></div>
<div style="flex-shrink: 1; max-width: 40%;"><img src="2023-12-11-21-19-21.png" style="width: 100%;"/></div>
<div style="flex-shrink: 1; max-width:40%;"><img src="2023-12-11-21-19-42.png" style="width: 100%;"/></div>
<div style="flex-shrink: 1; max-width:40%;"><img src="2023-12-11-21-20-02.png" style="width: 100%;"/></div>
</div>-->
<!--<div class="tile is-ancestor">
<div class="tile"><img src="2023-12-11-21-18-52.png" style="width: 100%;"/></div>
<div class="tile"><img src="2023-12-11-21-19-21.png" style="width: 100%;"/></div>
<div class="tile"><img src="2023-12-11-21-19-42.png" style="width: 100%;"/></div>
<div class="tile"><img src="2023-12-11-21-20-02.png" style="width: 100%;"/></div>
</div>-->
<!--[![2023-12-11-21-18-52.png](assets/2023-12-11-21-18-52.png)](assets/2023-12-11-21-18-52.png)
![](assets/2023-12-11-21-19-21.png)
![](assets/2023-12-11-21-19-42.png)
![](assets/2023-12-11-21-20-02.png)-->

{{#tile
:: ![](assets/2023-12-11-21-18-52.png)
:: ![](assets/2023-12-11-21-19-21.png)
:: ![](assets/2023-12-11-21-19-42.png)
:: ![](assets/2023-12-11-21-20-02.png)
}}

##### How to Use t-SNE Effectively

```info
:: Link: <https://distill.pub/2016/misread-tsne/>
```

> Although extremely useful for visualizing high-dimensional data, t-SNE plots can sometimes be mysterious or misleading. By exploring how it behaves in simple cases, we can learn to use it more effectively.

{{#tile
:: ![](assets/2023-12-11-21-20-41.png)
:: ![](assets/2023-12-11-21-20-50.png)
}}

##### Feature Visualization

```info
:: Link: <https://distill.pub/2017/feature-visualization/>
```
{{#tile
:: ![](assets/2023-12-11-21-25-35.png)
:: ![](assets/2023-12-11-21-26-22.png)
:: ![](assets/2023-12-11-21-26-39.png)
}}
##### Sequence Modeling with CTC

```info
:: Tagline: A visual guide to Connectionist Temporal Classification, an algorithm used to train deep neural networks in speech recognition, handwriting recognition and other sequence problems.
:: Link: <https://distill.pub/2017/ctc/>
```
{{#tile
:: ![](assets/2023-12-11-21-28-21.png)
:: ![](assets/2023-12-11-21-28-47.png)
:: ![](assets/2023-12-11-21-28-55.png)
:: ![](assets/2023-12-11-21-29-40.png)
}}

##### The Building Blocks of Interpretability

```info
:: Link: <https://distill.pub/2018/building-blocks/>
```

> Interpretability techniques are normally studied in isolation. 
> We explore the powerful interfaces that arise when you combine them — and the rich structure of this combinatorial space.
> For instance, by combining feature visualization (what is a neuron looking for?) with attribution (how does it affect the output?), we can explore how the network decides between labels like Labrador retriever and tiger cat.

{{#tile
:: ![](assets/2023-12-11-21-30-28.png)
}}

##### Feature-Wise Transformations

```info
:: Tagline: A simple and surprisingly effective family of conditioning mechanisms.
:: Link:  <https://distill.pub/2018/feature-wise-transformations/>
```

> Many real-world problems require integrating multiple sources of information. Sometimes these problems involve multiple, distinct modalities of information — vision, language, audio, etc. — as is required to understand a scene in a movie or answer a question about an image. Other times, these problems involve multiple sources of the same kind of input, i.e. when summarizing several documents or drawing one image in the style of another.

{{#tile
:: ![](assets/2023-12-11-21-35-12.png)
:: ![](assets/2023-12-11-21-34-43.png)
}}

##### Exploring Neural Networks with Activation Atlases

```info
:: Link: <https://distill.pub/2019/activation atlas/>
```

> By using feature inversion to visualize millions of activations from an image classification network, we create an explorable activation atlas of features the network has learned which can reveal how the network typically represents some concepts.

{{#tile
:: ![](assets/2023-12-11-21-38-32.png)
}}

##### Visualizing memorization in RNNs


```info
:: Tagline: Inspecting gradient magnitudes in context can be a powerful tool to see when recurrent units use short-term or long-term contextual understanding.
:: Link: <https://distill.pub/2019/memorization-in-rnns/>
```

> This article presents a qualitative visualization method for comparing recurrent units with regards to memorization and contextual understanding. The method is applied to the three recurrent units mentioned above: Nested LSTMs, LSTMs, and GRUs.

{{#tile
:: ![](assets/2023-12-11-21-39-17.png)
:: ![](assets/2023-12-11-21-40-40.png)
}}

##### Paths Perspective on Value Learning

```info
:: Tagline: A closer look at how Temporal Difference learning merges paths of experience for greater statistical efficiency.
:: Link: <https://distill.pub/2019/paths-perspective-on-value-learning/>
```

{{#tile
:: ![](assets/2023-12-11-21-41-50.png)
:: ![](assets/2023-12-11-21-42-31.png)
::![](assets/2023-12-11-21-42-47.png)
}}

##### Computing Receptive Fields of Convolutional Neural Networks

```info:
:: Tagline: Mathematical derivations and <a href="https://github.com/google-research/receptive_field">open-source library</a> to compute receptive fields of convnets, enabling the mapping of extracted features to input signals.
:: Link: <https://distill.pub/2019/computing-receptive-fields/>
```

{{#tile
:: ![](assets/2023-12-11-21-44-39.png)
}}

##### Visualizing Neural Networks with the Grand Tour

```info
:: Tagline: Using Visualization to Understand DNNs
:: Link: <https://distill.pub/2020/grand-tour/>
```

{{#tile
:: ![](assets/2023-12-11-21-47-52.png)
:: ![](assets/2023-12-11-21-48-12.png)
}}

> The Grand Tour is a classic visualization technique for high-dimensional point clouds that projects a high-dimensional dataset into two dimensions. Over time, the Grand Tour smoothly animates its projection so that every possible view of the dataset is (eventually) presented to the viewer. ...
>
> In this article, we show how to leverage the linearity of the Grand Tour to enable a number of capabilities that are uniquely useful to visualize the behavior of neural networks.
>
> Concretely, we present three use cases of interest: 
> 1. visualizing the training process as the network weights change, 
> 2. visualizing the layer-to-layer behavior as the data goes through the network\[,\] and
> 3. visualizing both how adversarial examples are crafted and how they fool a neural network.

##### Understanding RL (Reinforcement Learning) Vision {.pagetoc-exclude}

```info
:: Tagline: With diverse environments, we can analyze, diagnose and edit deep reinforcement learning models using attribution.
:: Link: <https://distill.pub/2020/understanding-rl-vision/>
```

{{#tile
:: ![](assets/2023-12-11-21-51-40.png)
:: ![](assets/2023-12-11-21-52-24.png)
:: ![](assets/2023-12-11-21-52-40.png)
:: ![](assets/2023-12-11-21-53-01.png)
}}